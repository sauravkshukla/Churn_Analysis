{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "687461e6-c8f7-47c8-89e0-03a5c80e9e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    roc_curve, precision_recall_curve, average_precision_score,\n",
    "    log_loss, matthews_corrcoef, balanced_accuracy_score\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# ================== File Paths ==================\n",
    "input_path = r\"C:\\Users\\Adity\\OneDrive\\Desktop\\Customer_Data.csv\"\n",
    "output_path = r\"C:\\Users\\Adity\\OneDrive\\Desktop\\Predicted_Churn.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b6f7621-e195-43e9-8c27-643b7a4062ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded:\n",
      "  Customer_ID  Gender  Age Married        State  Number_of_Referrals  \\\n",
      "0   19877-DEL    Male   35      No        Delhi                    7   \n",
      "1   58353-MAH  Female   45     Yes  Maharashtra                   14   \n",
      "2   25063-WES    Male   51      No  West Bengal                    4   \n",
      "3   59787-KAR    Male   79      No    Karnataka                    3   \n",
      "4   28544-TAM  Female   80      No   Tamil Nadu                    3   \n",
      "\n",
      "   Tenure_in_Months Value_Deal Phone_Service Multiple_Lines  ...  \\\n",
      "0                27        NaN           Yes             No  ...   \n",
      "1                13        NaN           Yes            Yes  ...   \n",
      "2                35     Deal 5           Yes             No  ...   \n",
      "3                21     Deal 4           Yes             No  ...   \n",
      "4                 8        NaN           Yes             No  ...   \n",
      "\n",
      "    Payment_Method Monthly_Charge Total_Charges Total_Refunds  \\\n",
      "0      Credit Card           65.6        593.30          0.00   \n",
      "1      Credit Card           -4.0        542.40         38.33   \n",
      "2  Bank Withdrawal           73.9        280.85          0.00   \n",
      "3  Bank Withdrawal           98.0       1237.85          0.00   \n",
      "4      Credit Card           83.9        267.40          0.00   \n",
      "\n",
      "  Total_Extra_Data_Charges Total_Long_Distance_Charges Total_Revenue  \\\n",
      "0                        0                      381.51        974.81   \n",
      "1                       10                       96.21        610.28   \n",
      "2                        0                      134.60        415.45   \n",
      "3                        0                      361.66       1599.51   \n",
      "4                        0                       22.14        289.54   \n",
      "\n",
      "  Customer_Status   Churn_Category                   Churn_Reason  \n",
      "0          Stayed              NaN                            NaN  \n",
      "1          Stayed              NaN                            NaN  \n",
      "2         Churned       Competitor  Competitor had better devices  \n",
      "3         Churned  Dissatisfaction        Product dissatisfaction  \n",
      "4         Churned  Dissatisfaction            Network reliability  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# ================== Load Data ==================\n",
    "df = pd.read_csv(input_path)\n",
    "print(\"‚úÖ Data loaded:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d47b4a1-736d-44f2-9a49-0adc7c5f4ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== Preprocessing ==================\n",
    "df = df.dropna(subset=['Customer_Status'])\n",
    "df = df.drop(['Customer_ID', 'Churn_Category', 'Churn_Reason'], axis=1, errors='ignore')\n",
    "\n",
    "columns_to_encode = [\n",
    "    'Gender', 'Married', 'State', 'Value_Deal', 'Phone_Service', 'Multiple_Lines',\n",
    "    'Internet_Service', 'Internet_Type', 'Online_Security', 'Online_Backup',\n",
    "    'Device_Protection_Plan', 'Premium_Support', 'Streaming_TV', 'Streaming_Movies',\n",
    "    'Streaming_Music', 'Unlimited_Data', 'Contract', 'Paperless_Billing',\n",
    "    'Payment_Method'\n",
    "]\n",
    "\n",
    "label_encoders = {}\n",
    "for col in columns_to_encode:\n",
    "    if col in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "df['Customer_Status'] = df['Customer_Status'].map({'Stayed': 0, 'Churned': 1})\n",
    "df = df.dropna()\n",
    "\n",
    "X = df.drop('Customer_Status', axis=1)\n",
    "y = df['Customer_Status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c7320fd-6796-4518-999d-2938aa563152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adity\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Logistic Regression Model Performance Metrics:\n",
      "Accuracy: 0.7795\n",
      "Precision: 0.6805\n",
      "Recall (Sensitivity): 0.5014\n",
      "F1-Score: 0.5774\n",
      "ROC AUC: 0.8096\n",
      "Average Precision: 0.6735\n",
      "Log Loss: 0.4773\n",
      "Matthews Correlation: 0.4421\n",
      "Balanced Accuracy: 0.7002\n",
      "Specificity: 0.8989\n",
      "False Positive Rate: 0.1011\n",
      "False Negative Rate: 0.4986\n",
      "Negative Predictive Value: 0.8077\n",
      "\n",
      "‚úÖ Confusion Matrix:\n",
      "[[756  85]\n",
      " [180 181]]\n",
      "\n",
      "‚úÖ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.90      0.85       841\n",
      "         1.0       0.68      0.50      0.58       361\n",
      "\n",
      "    accuracy                           0.78      1202\n",
      "   macro avg       0.74      0.70      0.71      1202\n",
      "weighted avg       0.77      0.78      0.77      1202\n",
      "\n",
      "\n",
      "üìä Convergence Info:\n",
      "Solver: saga\n",
      "Iterations used: 5000\n",
      "Max iterations: 5000\n",
      "Converged: False\n",
      "Tolerance: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/15 03:03:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/15 03:03:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ MLflow run completed. Run ID: cc7acbca7b724de0bed8df6f15aa16e3\n",
      "üìä Model convergence status: ‚ùå Did not converge\n",
      "üìä Iterations used: 5000/5000\n",
      "üèÉ View run LogisticRegression_Classifier_Fixed at: http://127.0.0.1:5000/#/experiments/635998505895616251/runs/cc7acbca7b724de0bed8df6f15aa16e3\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/635998505895616251\n"
     ]
    }
   ],
   "source": [
    "# ================== MLflow Setup ==================\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Churn_Prediction\")\n",
    "\n",
    "# ================== Solution 1: Increase max_iter and use better solver ==================\n",
    "# The most common solution is to increase max_iter and use a more robust solver\n",
    "\n",
    "with mlflow.start_run(run_name=\"LogisticRegression_Classifier_Fixed\") as run:\n",
    "    \n",
    "    # Option 1: Increase max_iter with liblinear solver (good for small datasets)\n",
    "    # model = LogisticRegression(max_iter=5000, solver='liblinear', random_state=42)\n",
    "    \n",
    "    # Option 2: Use saga solver (good for large datasets and L1/L2 regularization)\n",
    "    # model = LogisticRegression(max_iter=5000, solver='saga', random_state=42)\n",
    "    \n",
    "    # Option 3: Use newton-cg solver (good for small datasets, L2 only)\n",
    "    # model = LogisticRegression(max_iter=5000, solver='newton-cg', random_state=42)\n",
    "    \n",
    "    # Option 4: Recommended - Use saga with increased iterations\n",
    "    model = LogisticRegression(\n",
    "        max_iter=5000,\n",
    "        solver='saga',\n",
    "        random_state=42,\n",
    "        tol=1e-4,  # Tolerance for stopping criteria\n",
    "        warm_start=False\n",
    "    )\n",
    "    \n",
    "    # ================== Alternative: Scale the data first ==================\n",
    "    # If convergence is still an issue, scale the features\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    # Uncomment these lines if you want to scale the data:\n",
    "    # scaler = StandardScaler()\n",
    "    # X_train_scaled = scaler.fit_transform(X_train)\n",
    "    # X_test_scaled = scaler.transform(X_test)\n",
    "    # model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # For now, let's use the original data with improved solver\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # ================== Evaluate ==================\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probability of class 1 (churned)\n",
    "    \n",
    "    # Basic metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    \n",
    "    # Advanced metrics\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    avg_precision = average_precision_score(y_test, y_pred_proba)\n",
    "    log_loss_score = log_loss(y_test, y_pred_proba)\n",
    "    matthews_corr = matthews_corrcoef(y_test, y_pred)\n",
    "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Confusion matrix components\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Additional derived metrics\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = tp / (tp + fn)  # Same as recall\n",
    "    false_positive_rate = fp / (fp + tn)\n",
    "    false_negative_rate = fn / (fn + tp)\n",
    "    positive_predictive_value = tp / (tp + fp)  # Same as precision\n",
    "    negative_predictive_value = tn / (tn + fn)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n‚úÖ Logistic Regression Model Performance Metrics:\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "    print(f\"Log Loss: {log_loss_score:.4f}\")\n",
    "    print(f\"Matthews Correlation: {matthews_corr:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "    print(f\"Specificity: {specificity:.4f}\")\n",
    "    print(f\"False Positive Rate: {false_positive_rate:.4f}\")\n",
    "    print(f\"False Negative Rate: {false_negative_rate:.4f}\")\n",
    "    print(f\"Negative Predictive Value: {negative_predictive_value:.4f}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"\\n‚úÖ Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # ================== Check Convergence Status ==================\n",
    "    convergence_info = {\n",
    "        'n_iter': model.n_iter_[0] if hasattr(model, 'n_iter_') else None,\n",
    "        'converged': model.n_iter_[0] < model.max_iter if hasattr(model, 'n_iter_') else True,\n",
    "        'max_iter': model.max_iter,\n",
    "        'solver': model.solver,\n",
    "        'tol': model.tol\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüìä Convergence Info:\")\n",
    "    print(f\"Solver: {convergence_info['solver']}\")\n",
    "    print(f\"Iterations used: {convergence_info['n_iter']}\")\n",
    "    print(f\"Max iterations: {convergence_info['max_iter']}\")\n",
    "    print(f\"Converged: {convergence_info['converged']}\")\n",
    "    print(f\"Tolerance: {convergence_info['tol']}\")\n",
    "\n",
    "    # ================== Create Visualizations ==================\n",
    "    \n",
    "    # 1. ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Logistic Regression - ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(\"lr_roc_curve.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Precision-Recall Curve\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall_curve, precision_curve, color='blue', lw=2, \n",
    "             label=f'PR curve (AP = {avg_precision:.4f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Logistic Regression - Precision-Recall Curve')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(\"lr_precision_recall_curve.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Confusion Matrix Heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Stayed', 'Churned'], \n",
    "                yticklabels=['Stayed', 'Churned'])\n",
    "    plt.title('Logistic Regression - Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(\"lr_confusion_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Feature Coefficients Plot\n",
    "    if hasattr(model, \"coef_\"):\n",
    "        coef = model.coef_[0]\n",
    "        feature_importance_df = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'coefficient': coef,\n",
    "            'abs_coefficient': np.abs(coef)\n",
    "        }).sort_values('abs_coefficient', ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top_features = feature_importance_df.head(20)\n",
    "        colors = ['red' if x < 0 else 'green' for x in top_features['coefficient']]\n",
    "        plt.barh(range(len(top_features)), top_features['coefficient'], color=colors)\n",
    "        plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "        plt.xlabel('Coefficient Value')\n",
    "        plt.title('Top 20 Feature Coefficients (Logistic Regression)')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"lr_coefficients.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # 5. Prediction Distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(y_pred_proba[y_test == 0], bins=50, alpha=0.7, label='Stayed', color='blue')\n",
    "    plt.hist(y_pred_proba[y_test == 1], bins=50, alpha=0.7, label='Churned', color='red')\n",
    "    plt.xlabel('Predicted Probability of Churn')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Logistic Regression - Distribution of Predicted Probabilities')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(\"lr_prediction_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 6. Calibration Plot\n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(y_test, y_pred_proba, n_bins=10)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"Logistic Regression\")\n",
    "    plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "    plt.xlabel('Mean Predicted Probability')\n",
    "    plt.ylabel('Fraction of Positives')\n",
    "    plt.title('Logistic Regression - Calibration Plot')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(\"lr_calibration_plot.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 7. Coefficient Distribution\n",
    "    if hasattr(model, \"coef_\"):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(coef, bins=20, alpha=0.7, color='purple', edgecolor='black')\n",
    "        plt.xlabel('Coefficient Value')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Distribution of Logistic Regression Coefficients')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(\"lr_coef_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # 8. Odds Ratios Plot\n",
    "    if hasattr(model, \"coef_\"):\n",
    "        odds_ratios = np.exp(coef)\n",
    "        odds_df = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'odds_ratio': odds_ratios,\n",
    "            'log_odds': coef\n",
    "        }).sort_values('odds_ratio', ascending=False)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top_odds = odds_df.head(20)\n",
    "        colors = ['red' if x < 1 else 'green' for x in top_odds['odds_ratio']]\n",
    "        plt.barh(range(len(top_odds)), top_odds['odds_ratio'], color=colors)\n",
    "        plt.yticks(range(len(top_odds)), top_odds['feature'])\n",
    "        plt.xlabel('Odds Ratio')\n",
    "        plt.title('Top 20 Feature Odds Ratios (Logistic Regression)')\n",
    "        plt.axvline(x=1, color='black', linestyle='--', alpha=0.7)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"lr_odds_ratios.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # 9. Convergence Analysis Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    convergence_data = {\n",
    "        'Solver': convergence_info['solver'],\n",
    "        'Iterations Used': convergence_info['n_iter'],\n",
    "        'Max Iterations': convergence_info['max_iter'],\n",
    "        'Converged': 'Yes' if convergence_info['converged'] else 'No'\n",
    "    }\n",
    "    \n",
    "    # Create a simple bar chart for convergence info\n",
    "    plt.bar(['Iterations Used', 'Max Iterations'], \n",
    "            [convergence_info['n_iter'], convergence_info['max_iter']], \n",
    "            color=['green' if convergence_info['converged'] else 'red', 'gray'])\n",
    "    plt.ylabel('Number of Iterations')\n",
    "    plt.title(f'Convergence Analysis - {convergence_info[\"solver\"]} Solver')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(\"lr_convergence_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # ================== Log to MLflow ==================\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"max_iter\", model.max_iter)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_param(\"test_size\", 0.2)\n",
    "    mlflow.log_param(\"n_features\", X.shape[1])\n",
    "    mlflow.log_param(\"n_samples\", X.shape[0])\n",
    "    mlflow.log_param(\"class_balance\", f\"{(y==0).sum()}:{(y==1).sum()}\")\n",
    "    mlflow.log_param(\"solver\", model.solver)\n",
    "    mlflow.log_param(\"penalty\", model.penalty)\n",
    "    mlflow.log_param(\"C\", model.C)\n",
    "    mlflow.log_param(\"tol\", model.tol)\n",
    "    \n",
    "    # Log convergence info\n",
    "    mlflow.log_param(\"n_iter_actual\", convergence_info['n_iter'])\n",
    "    mlflow.log_param(\"converged\", convergence_info['converged'])\n",
    "    mlflow.log_param(\"convergence_status\", \"Converged\" if convergence_info['converged'] else \"Did not converge\")\n",
    "    \n",
    "    # Log basic metrics\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    \n",
    "    # Log advanced metrics\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "    mlflow.log_metric(\"average_precision\", avg_precision)\n",
    "    mlflow.log_metric(\"log_loss\", log_loss_score)\n",
    "    mlflow.log_metric(\"matthews_correlation\", matthews_corr)\n",
    "    mlflow.log_metric(\"balanced_accuracy\", balanced_acc)\n",
    "    \n",
    "    # Log confusion matrix components\n",
    "    mlflow.log_metric(\"true_positives\", tp)\n",
    "    mlflow.log_metric(\"false_positives\", fp)\n",
    "    mlflow.log_metric(\"true_negatives\", tn)\n",
    "    mlflow.log_metric(\"false_negatives\", fn)\n",
    "    \n",
    "    # Log additional derived metrics\n",
    "    mlflow.log_metric(\"specificity\", specificity)\n",
    "    mlflow.log_metric(\"sensitivity\", sensitivity)\n",
    "    mlflow.log_metric(\"false_positive_rate\", false_positive_rate)\n",
    "    mlflow.log_metric(\"false_negative_rate\", false_negative_rate)\n",
    "    mlflow.log_metric(\"positive_predictive_value\", positive_predictive_value)\n",
    "    mlflow.log_metric(\"negative_predictive_value\", negative_predictive_value)\n",
    "    \n",
    "    # Log Logistic Regression specific metrics\n",
    "    if hasattr(model, \"coef_\"):\n",
    "        mlflow.log_metric(\"max_abs_coefficient\", np.max(np.abs(coef)))\n",
    "        mlflow.log_metric(\"min_abs_coefficient\", np.min(np.abs(coef)))\n",
    "        mlflow.log_metric(\"mean_abs_coefficient\", np.mean(np.abs(coef)))\n",
    "        mlflow.log_metric(\"std_coefficient\", np.std(coef))\n",
    "        mlflow.log_metric(\"max_odds_ratio\", np.max(odds_ratios))\n",
    "        mlflow.log_metric(\"min_odds_ratio\", np.min(odds_ratios))\n",
    "        \n",
    "        # Log feature name as parameter and coefficient value as metric\n",
    "        mlflow.log_param(\"feature_with_max_coef\", feature_importance_df.iloc[0]['feature'])\n",
    "        mlflow.log_metric(\"max_coef_value\", feature_importance_df.iloc[0]['abs_coefficient'])\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model, \"logistic_regression_model\")\n",
    "    \n",
    "    # Log all artifacts\n",
    "    mlflow.log_artifact(\"lr_roc_curve.png\")\n",
    "    mlflow.log_artifact(\"lr_precision_recall_curve.png\")\n",
    "    mlflow.log_artifact(\"lr_confusion_matrix.png\")\n",
    "    mlflow.log_artifact(\"lr_coefficients.png\")\n",
    "    mlflow.log_artifact(\"lr_prediction_distribution.png\")\n",
    "    mlflow.log_artifact(\"lr_calibration_plot.png\")\n",
    "    mlflow.log_artifact(\"lr_coef_distribution.png\")\n",
    "    mlflow.log_artifact(\"lr_odds_ratios.png\")\n",
    "    mlflow.log_artifact(\"lr_convergence_analysis.png\")\n",
    "    \n",
    "    # Save and log model files\n",
    "    joblib.dump(model, \"logistic_regression_model.pkl\")\n",
    "    joblib.dump(label_encoders, \"label_encoders.pkl\")\n",
    "    mlflow.log_artifact(\"logistic_regression_model.pkl\")\n",
    "    mlflow.log_artifact(\"label_encoders.pkl\")\n",
    "    \n",
    "    # Log feature importance/coefficients as JSON\n",
    "    if hasattr(model, \"coef_\"):\n",
    "        feature_importance_df.to_json(\"lr_feature_coefficients.json\")\n",
    "        mlflow.log_artifact(\"lr_feature_coefficients.json\")\n",
    "        \n",
    "        odds_df.to_json(\"lr_odds_ratios.json\")\n",
    "        mlflow.log_artifact(\"lr_odds_ratios.json\")\n",
    "    \n",
    "    # Log model summary with convergence info\n",
    "    model_summary = {\n",
    "        'model_type': 'LogisticRegression',\n",
    "        'n_features': int(X.shape[1]),\n",
    "        'n_samples': int(X.shape[0]),\n",
    "        'converged': bool(convergence_info['converged']),\n",
    "        'n_iter_actual': int(convergence_info['n_iter']),\n",
    "        'max_iter': int(convergence_info['max_iter']),\n",
    "        'solver': str(model.solver),\n",
    "        'penalty': str(model.penalty),\n",
    "        'C': float(model.C),\n",
    "        'tol': float(model.tol)\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    with open(\"lr_model_summary.json\", \"w\") as f:\n",
    "        json.dump(model_summary, f, indent=2)\n",
    "    mlflow.log_artifact(\"lr_model_summary.json\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ MLflow run completed. Run ID: {run.info.run_id}\")\n",
    "    print(f\"üìä Model convergence status: {'‚úÖ Converged' if convergence_info['converged'] else '‚ùå Did not converge'}\")\n",
    "    print(f\"üìä Iterations used: {convergence_info['n_iter']}/{convergence_info['max_iter']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9aa33efd-5bf8-402d-8fe6-2d15890c0f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Churned customer predictions saved to: C:\\Users\\Adity\\OneDrive\\Desktop\\Predicted_Churn.csv\n",
      "üìä Total customers predicted to churn: 681\n",
      "üìä Churn rate: 34.17%\n",
      "üìä Average churn probability: 0.3334\n",
      "üìä High-risk customers (>80% churn prob): 70\n",
      "üìä Medium-risk customers (50-80% churn prob): 611\n",
      "üìä Low-risk customers (<50% churn prob): 1312\n",
      "\n",
      "üìä Top 5 Positive Risk Factors (increase churn probability):\n",
      "   ‚Ä¢ Internet_Type: 0.2931\n",
      "   ‚Ä¢ Paperless_Billing: 0.2249\n",
      "   ‚Ä¢ Streaming_Movies: 0.1430\n",
      "   ‚Ä¢ Value_Deal: 0.0818\n",
      "   ‚Ä¢ Streaming_Music: 0.0682\n",
      "\n",
      "üìä Top 5 Negative Risk Factors (decrease churn probability):\n",
      "   ‚Ä¢ Contract: -1.3223\n",
      "   ‚Ä¢ Online_Security: -0.4775\n",
      "   ‚Ä¢ Premium_Support: -0.4090\n",
      "   ‚Ä¢ Payment_Method: -0.2449\n",
      "   ‚Ä¢ Unlimited_Data: -0.1996\n"
     ]
    }
   ],
   "source": [
    "# ================== Predict on Entire Data ==================\n",
    "new_data = pd.read_csv(input_path)\n",
    "original_data = new_data.copy()\n",
    "\n",
    "new_data = new_data.drop(['Customer_ID', 'Customer_Status', 'Churn_Category', 'Churn_Reason'], axis=1, errors='ignore')\n",
    "new_data = new_data.dropna()\n",
    "\n",
    "for col in new_data.select_dtypes(include='object').columns:\n",
    "    if col in label_encoders:\n",
    "        new_data[col] = label_encoders[col].transform(new_data[col].astype(str))\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No encoder found for column: {col}. Skipping.\")\n",
    "\n",
    "new_predictions = model.predict(new_data)\n",
    "new_predictions_proba = model.predict_proba(new_data)[:, 1]\n",
    "\n",
    "original_data = original_data.iloc[:len(new_predictions)].copy()\n",
    "original_data['Customer_Status_Predicted'] = new_predictions\n",
    "original_data['Churn_Probability'] = new_predictions_proba\n",
    "\n",
    "churned = original_data[original_data['Customer_Status_Predicted'] == 1]\n",
    "churned.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Churned customer predictions saved to: {output_path}\")\n",
    "print(f\"üìä Total customers predicted to churn: {len(churned)}\")\n",
    "print(f\"üìä Churn rate: {len(churned)/len(original_data)*100:.2f}%\")\n",
    "print(f\"üìä Average churn probability: {new_predictions_proba.mean():.4f}\")\n",
    "print(f\"üìä High-risk customers (>80% churn prob): {sum(new_predictions_proba > 0.8)}\")\n",
    "print(f\"üìä Medium-risk customers (50-80% churn prob): {sum((new_predictions_proba > 0.5) & (new_predictions_proba <= 0.8))}\")\n",
    "print(f\"üìä Low-risk customers (<50% churn prob): {sum(new_predictions_proba <= 0.5)}\")\n",
    "\n",
    "# Display top risk factors\n",
    "if hasattr(model, \"coef_\"):\n",
    "    print(f\"\\nüìä Top 5 Positive Risk Factors (increase churn probability):\")\n",
    "    positive_coef = feature_importance_df[feature_importance_df['coefficient'] > 0].head(5)\n",
    "    for idx, row in positive_coef.iterrows():\n",
    "        print(f\"   ‚Ä¢ {row['feature']}: {row['coefficient']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nüìä Top 5 Negative Risk Factors (decrease churn probability):\")\n",
    "    negative_coef = feature_importance_df[feature_importance_df['coefficient'] < 0].head(5)\n",
    "    for idx, row in negative_coef.iterrows():\n",
    "        print(f\"   ‚Ä¢ {row['feature']}: {row['coefficient']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
